def AlexNet():
    m = keras.models.Sequential()

    #Note the 256,256,3 input (from our Mercer Images)
    m.add(keras.layers.Conv2D(filters=96, input_shape=(256,256,3), kernel_size=(11,11), strides=(4,4), padding='same'))
    m.add(keras.layers.normalization.BatchNormalization())
    m.add(keras.layers.Activation('relu'))
    m.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))

    #Convolve
    m.add(keras.layers.Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))
    m.add(keras.layers.BatchNormalization())
    m.add(keras.layers.Activation('relu'))
    
    #Maxpool
    m.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))

    #Convolve
    m.add(keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))
    m.add(keras.layers.BatchNormalization())
    m.add(keras.layers.Activation('relu'))

    #Convolve
    m.add(keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))
    m.add(keras.layers.BatchNormalization())
    m.add(keras.layers.Activation('relu'))

    #Convolve
    m.add(keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))
    m.add(keras.layers.BatchNormalization())
    m.add(keras.layers.Activation('relu'))
    m.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))

    #Affine Layer for Estimates
    m.add(keras.layers.Flatten())
    m.add(keras.layers.Dense(4096, input_shape=(32,32,3,)))
    m.add(keras.layers.BatchNormalization())
    m.add(keras.layers.Activation('relu'))

    #Dropout Regularization
    m.add(keras.layers.Dropout(0.4))

    #Affine
    m.add(keras.layers.Dense(4096))
    m.add(keras.layers.BatchNormalization())
    m.add(keras.layers.Activation('relu'))
    
    #Dropout Regularization
    m.add(keras.layers.Dropout(0.4))

    #Affine
    m.add(keras.layers.Dense(1000))
    m.add(keras.layers.BatchNormalization())
    m.add(keras.layers.Activation('relu'))

    #DropoutRegularization
    m.add(keras.layers.Dropout(0.4))

    #Final Affine (21 Scores, one for each class in our Mercer)
    m.add(keras.layers.Dense(21))
    m.add(keras.layers.BatchNormalization())
    m.add(keras.layers.Activation('softmax'))

    #Same optimizer for all of these examples, for a fair comparison.
    m.compile(optimizer=keras.optimizers.SGD(learning_rate=.001),
                                            loss='categorical_hinge',
                                            metrics=['categorical_accuracy'])

    return(m)

dataGenerator = keras.preprocessing.image.ImageDataGenerator()
train = dataGenerator.flow_from_directory("./mercerImages", class_mode='categorical', batch_size=32)
    
AlexNet = AlexNet()
AlexNet.fit(train, epochs=15)
